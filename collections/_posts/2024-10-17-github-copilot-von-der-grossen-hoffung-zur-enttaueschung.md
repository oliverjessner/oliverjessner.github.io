---
layout: post
title: 'Copilot: Von der gro√üen Hoffnung zur Entt√§uschung? üöÄ'
date: 2024-10-16 01:35:00 +0200
authors: ['oliver_jessner']
meta_og_type: 'article'
categories:
    - software-development
    - KI
description: 'Viele Entwickler sind begeistert von der KI-Unterst√ºtzung, doch erste Stimmen werden laut, die das Tool kritisch hinterfragen. Marc Benioff, CEO von Salesforce, spricht sogar von einer gro√üen Entt√§uschung. Sind wir zu abh√§ngig von automatisch generiertem Code? Und was passiert mit unseren grundlegenden Programmierf√§higkeiten? ü§î'
thumbnail: '/assets/images/gen/blog/github-copilot-von-der-grossen-hoffung-zur-enttaueschung/header_thumbnail.webp'
image: '/assets/images/gen/blog/github-copilot-von-der-grossen-hoffung-zur-enttaueschung/header.webp'
---

### Copilot: Von der gro√üen Hoffnung zur Entt√§uschung?

Viele Entwickler und Unternehmen waren von (GitHub) Copilot begeistert, doch es scheint, als w√ºrde diese anf√§ngliche Euphorie langsam in Ern√ºchterung umschlagen. Marc Benioff, CEO von Salesforce, lie√ü k√ºrzlich in einem Interview verlauten, dass zahlreiche Kunden von Microsofts Copilot entt√§uscht seien. Er sagte: ‚ÄûViele Kunden sind entt√§uscht von dem, was sie von Microsoft Copilot gekauft haben, weil sie nicht die Genauigkeit und die Antworten bekommen, die sie sich erhofft hatten. Microsoft hat viele Kunden mit seiner KI entt√§uscht.‚Äú

Wenn ihr GitHub Copilot noch nicht kennt: Es handelt sich um ein KI-gest√ºtztes Tool, das Entwicklern beim Schreiben von Code hilft, indem es automatisch Codevorschl√§ge liefert. Doch warum sind Kunden wie Marc Benioff der Meinung, dass Copilot nicht h√§lt, was es verspricht? Copilot ist sehr √§hnlich zu GitHub Copilot, schlummert in diesem Fall jedoch nur in Office und MS-Produkten.

### Die Erwartungen an KI-gest√ºtzte Systeme

Zun√§chst einmal sollten wir uns klar dar√ºber sein, dass Tools wie GitHub Copilot keine Menschen ersetzen sollen, sondern sie unterst√ºtzen. Und in den meisten F√§llen funktioniert das auch ganz gut ‚Äì man muss viel weniger Boilerplate-Code schreiben, was eine enorme Zeitersparnis bedeutet. Aber reicht das aus?

Interessanterweise machte Benioff diese Aussage im Vorfeld der Einf√ºhrung von Salesforce's eigener KI-Plattform, Agentforce, auf der j√§hrlichen Dreamforce-Konferenz. Ein Schelm, wer dabei B√∂ses denkt! Es ist ein klassisches Beispiel f√ºr das ‚ÄûMitbewerber schlechtreden‚Äú ‚Äì nur um anschlie√üend das eigene Produkt in den Vordergrund zu r√ºcken. So l√§uft das Spiel in der Tech-Branche.

### Ist Benioff der Einzige, der Copilot kritisiert?

Ganz und gar nicht. Ein Artikel, der meinen Social Media Feed beherrscht hat, tr√§gt den Titel ‚ÄûWhy Copilot is Making Programmers Worse at Programming‚Äú von Darren Horrocks. Der Artikel beleuchtet einige der Risiken, die mit Tools wie Copilot einhergehen.

#### Verlust grundlegender Programmierf√§higkeiten

Einer der gr√∂√üten Kritikpunkte ist die schleichende Erosion grundlegender Programmierf√§higkeiten. Fr√ºher mussten Entwickler Probleme eigenst√§ndig l√∂sen, Algorithmen verstehen und den Code bis ins kleinste Detail durchdenken. Heute springen viele auf die schnellen L√∂sungen von Copilot auf und vernachl√§ssigen dabei das tiefere Verst√§ndnis.

#### √úberm√§√üige Abh√§ngigkeit von generiertem Code

Ein weiteres Problem ist die Gefahr, sich zu sehr auf automatisch generierten Code zu verlassen. Dieser mag auf den ersten Blick funktionieren, doch oft sind diese L√∂sungen weder die effizientesten noch die sichersten. Programmierer m√ºssen den generierten Code hinterfragen und √ºberpr√ºfen ‚Äì etwas, das viele jedoch aus Bequemlichkeit √ºberspringen.

#### Mangelndes Verantwortungsbewusstsein

Wenn der Code automatisch generiert wird, neigen Entwickler dazu, die Verantwortung f√ºr ihn abzugeben. Schlie√ülich hat die KI ihn erstellt, also muss er korrekt sein, oder? Falsch. Der Entwickler bleibt verantwortlich und sollte den Code √ºberpr√ºfen und verbessern.

#### Reduzierte Lernm√∂glichkeiten

Eine der sch√∂nsten Seiten der Softwareentwicklung ist die st√§ndige M√∂glichkeit, zu lernen und besser zu werden. Wenn ein Tool wie Copilot die Antwort sofort liefert, fehlt oft die Motivation, tiefer in das Problem einzutauchen und alternative L√∂sungen zu suchen.

#### Abh√§ngigkeit von propriet√§ren Tools

Ein weiterer Nachteil ist die Abh√§ngigkeit von propriet√§ren Plattformen wie GitHub Copilot. Was passiert, wenn die Tools versagen oder sich die Bedingungen √§ndern? Entwickler sollten sich nicht von einem einzigen System abh√§ngig machen, sondern weiterhin offen f√ºr neue Technologien und Community-L√∂sungen bleiben.

#### Falsches Gef√ºhl von Expertise

Besonders gef√§hrlich ist, dass solche Tools ein falsches Gef√ºhl von Expertise vermitteln k√∂nnen. Nur weil man schnell funktionierenden Code generiert, hei√üt das nicht, dass man die zugrunde liegende Technologie wirklich versteht. Gerade bei komplexeren Bereichen wie Performance-Optimierung oder Sicherheit kann dies zu schwerwiegenden Fehlern f√ºhren.

### Fazit

Wir stehen vor einer Herausforderung: Wie k√∂nnen wir Teams aufbauen, weiterentwickeln und f√∂rdern, die KI-Tools wie Copilot nutzen, ohne dabei die Kernkompetenzen zu verlieren? Es gilt, die richtige Balance zu finden ‚Äì zwischen maximaler Effizienz durch KI und dem Erhalt wichtiger Programmierf√§higkeiten. F√ºr Startups ist dies besonders spannend, da es noch nie so einfach war, ein MVP zu entwickeln. Doch gleichzeitig lauern die Gefahren, wenn unerfahrene Teams zu stark auf KI-Tools vertrauen.

Deshalb: Core Skills sind immer wichtig! Wenn ihr eure F√§higkeiten in JavaScript verbessern wollt, k√∂nnt ihr auf mein vollst√§ndiges Tutorial verlinken. Oder ihr h√∂rt euch meine Gedanken dazu an, wie der AWS-CEO glaubt, dass wir in 24 Monaten keine Entwickler mehr brauchen. Bis dahin ‚Äì baba!

Hast du schon mein letztes Quartals Update gelesen? [Hier geht's zum Artikel](/blog/2024-10-11-update-q3-2024/).
